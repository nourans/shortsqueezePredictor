{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load Stock Data\n",
    "with open('alphaVanData_AMC_full_daily.json', 'r') as stock_file:\n",
    "    stock_data = json.load(stock_file)\n",
    "\n",
    "# Extract Time Series (Daily)\n",
    "stock_df = pd.DataFrame.from_dict(stock_data[\"Time Series (Daily)\"], orient=\"index\")\n",
    "stock_df = stock_df.sort_index()  # Sort by date\n",
    "stock_df = stock_df.astype(float)  # Convert columns to numeric\n",
    "stock_df = stock_df[[\"4. close\", \"5. volume\"]]  # Use Close and Volume\n",
    "\n",
    "# Normalize Stock Data\n",
    "scaler = MinMaxScaler()\n",
    "stock_df_scaled = scaler.fit_transform(stock_df)\n",
    "\n",
    "# Load Social Media Data\n",
    "with open('redditData.json', 'r') as reddit_file:\n",
    "    reddit_data = json.load(reddit_file)\n",
    "\n",
    "# Convert Social Media JSON to DataFrame\n",
    "reddit_df = pd.DataFrame(reddit_data)  # Fill [insert logic to handle redditData.json format] here\n",
    "reddit_df[\"date\"] = pd.to_datetime(reddit_df[\"date\"])  # Parse dates\n",
    "reddit_df = reddit_df.sort_values(\"date\")\n",
    "\n",
    "# Aggregate Sentiment Data by Date\n",
    "reddit_df[\"sentiment_score\"] = reddit_df[\"upvotes\"] * reddit_df[\"sentiment\"]  # Example calculation\n",
    "social_features = reddit_df.groupby(\"date\")[[\"mentions\", \"sentiment_score\"]].sum()\n",
    "\n",
    "# Combine Stock and Social Media Data\n",
    "combined_df = pd.merge(stock_df, social_features, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "########\n",
    "# Define short squeeze criteria\n",
    "price_increase_threshold = 0.2  # 20% price increase within a day\n",
    "volume_increase_threshold = 2  # volume doubles compared to the previous day\n",
    "\n",
    "# Create sequences and label targets based on short squeeze criteria\n",
    "X, y = [], []\n",
    "for i in range(len(combined_df) - sequence_length - 1):  # Avoid index out of range\n",
    "    # Get the sequence\n",
    "    X.append(combined_df.iloc[i:i + sequence_length].values)\n",
    "    \n",
    "    # Check short squeeze conditions for the target day\n",
    "    current_price = combined_df.iloc[i + sequence_length - 1, 0]  # 'close' price on the last day of the sequence\n",
    "    next_price = combined_df.iloc[i + sequence_length, 0]  # 'close' price on the next day\n",
    "    current_volume = combined_df.iloc[i + sequence_length - 1, 1]  # 'volume' on the last day of the sequence\n",
    "    next_volume = combined_df.iloc[i + sequence_length, 1]  # 'volume' on the next day\n",
    "    \n",
    "    price_increase = (next_price - current_price) / current_price\n",
    "    volume_increase = next_volume / current_volume\n",
    "    \n",
    "    # Label as 1 if both criteria are met, otherwise 0\n",
    "    if price_increase > price_increase_threshold and volume_increase > volume_increase_threshold:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow_addons.layers import TCN\n",
    "\n",
    "# Build TCN Model\n",
    "TCNmodel = Sequential([\n",
    "    TCN(input_shape=(sequence_length, X.shape[2]), return_sequences=False),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Predict probability of short squeeze\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "TCNmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "TCNmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = TCNmodel.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,  # optimal number of epochs\n",
    "    batch_size=32,  # optimal batch size\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the Test Set\n",
    "test_loss, test_accuracy = TCNmodel.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Predict on New Data\n",
    "predictions = TCNmodel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "TCNmodel.save('short_squeeze_tcn_model.h5')\n",
    "\n",
    "# Save Scalers\n",
    "import joblib\n",
    "joblib.dump(scaler, 'stock_data_scaler.pkl')  # Save the stock data scaler\n",
    "# FILL: logic to save social media scaler if used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compare predictions with true labels\n",
    "plt.plot(y_test, label='True Values')\n",
    "plt.plot(predictions, label='Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
